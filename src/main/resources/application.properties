spring.application.name=ragchat

vaadin.launch-browser=true
vaadin.allowed-packages=org.jbareaud.ragchat

chat.service.provider=SIMPLE
chat.service.content-retriever.max-results=8
chat.service.memory-provider.max-messages=10

# Ollama
langchain4j.chat-model.api-key=ollama
langchain4j.chat-model.base-url=http://localhost:11434
langchain4j.chat-model.model-name=mistral:latest
# Generally 0.0 is recommended, but 0.3 allows some stylistic leeway when displaying answers from a raw mediawiki-formatted knowledge base
langchain4j.chat-model.temperature=0.3

# Debug
logging.level.dev.langchain4j=DEBUG
logging.level.dev.ai4j.openai4j=DEBUG
