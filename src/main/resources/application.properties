spring.application.name=ragchat

vaadin.launch-browser=true
vaadin.allowed-packages=org.jbareaud.ragchat

rag-chat.content-retriever-max-results=10
rag-chat.memory-provider-max-messages=10

# Ollama
rag-chat.chat-ollama-base-url=http://localhost:11434
# Generally 0.0 is recommended, but 0.3 allows some stylistic leeway when displaying answers from a raw mediawiki-formatted knowledge base
rag-chat.chat-temperature=0.3

rag-chat.scoring-enabled=true
rag-chat.scoring-path-to-model=D:\\LLM\\models\\ONNX\\bge-reranker-v2-m3-onnx\\model.onnx
rag-chat.scoring-path-to-tokenizer=D:\\LLM\\models\\ONNX\\bge-reranker-v2-m3-onnx\\tokenizer.json
rag-chat.scoring-min-score=0.7

rag-chat.splitter-max-chars=500
rag-chat.splitter-overlap-chars=100

# Debug
logging.level.dev.langchain4j=DEBUG
logging.level.dev.ai4j.openai4j=DEBUG
logging.level.org.jbareaud.ragchat=DEBUG